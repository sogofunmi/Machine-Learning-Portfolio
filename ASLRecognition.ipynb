{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-10T01:56:13.013602Z",
     "iopub.status.busy": "2024-05-10T01:56:13.012938Z",
     "iopub.status.idle": "2024-05-10T01:56:13.021208Z",
     "shell.execute_reply": "2024-05-10T01:56:13.020176Z",
     "shell.execute_reply.started": "2024-05-10T01:56:13.013566Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T01:56:16.933379Z",
     "iopub.status.busy": "2024-05-10T01:56:16.932619Z",
     "iopub.status.idle": "2024-05-10T01:56:16.938666Z",
     "shell.execute_reply": "2024-05-10T01:56:16.937629Z",
     "shell.execute_reply.started": "2024-05-10T01:56:16.933345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T01:56:22.384828Z",
     "iopub.status.busy": "2024-05-10T01:56:22.383895Z",
     "iopub.status.idle": "2024-05-10T01:56:22.396732Z",
     "shell.execute_reply": "2024-05-10T01:56:22.395598Z",
     "shell.execute_reply.started": "2024-05-10T01:56:22.384773Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(size=(128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "test_transform = transform = transforms.Compose([\n",
    "    transforms.Resize(size=(128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])  \n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, split_ratio=0.8, transform=None, train=True):\n",
    "        self.data_dir = data_dir\n",
    "        self.split_ratio = split_ratio\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.dataset = datasets.ImageFolder(root=data_dir, transform=None)\n",
    "        self.classes = self.dataset.classes \n",
    "        \n",
    "        \n",
    "        indices = list(range(len(self.dataset)))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        \n",
    "        split_index = int(self.split_ratio * len(indices))\n",
    "        if train:\n",
    "            self.indices = indices[:split_index]\n",
    "        else:\n",
    "            self.indices = indices[split_index:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_in_dataset = self.indices[idx]\n",
    "        image, label = self.dataset[idx_in_dataset]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T01:56:43.873588Z",
     "iopub.status.busy": "2024-05-10T01:56:43.873192Z",
     "iopub.status.idle": "2024-05-10T01:56:59.544125Z",
     "shell.execute_reply": "2024-05-10T01:56:59.543287Z",
     "shell.execute_reply.started": "2024-05-10T01:56:43.873557Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(data_dir=image_path, transform=train_transform, train=True)\n",
    "test_dataset = CustomDataset(data_dir=image_path, transform=test_transform, train=False)\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "valid_size = 0.2\n",
    "\n",
    "\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split_val = int(np.floor(valid_size * num_train))\n",
    "\n",
    "valid_idx, train_idx = indices[:split_val], indices[split_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T01:57:13.785016Z",
     "iopub.status.busy": "2024-05-10T01:57:13.784649Z",
     "iopub.status.idle": "2024-05-10T01:57:13.790647Z",
     "shell.execute_reply": "2024-05-10T01:57:13.789681Z",
     "shell.execute_reply.started": "2024-05-10T01:57:13.784990Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "    sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION USING CUSTOM CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T01:57:17.264049Z",
     "iopub.status.busy": "2024-05-10T01:57:17.263667Z",
     "iopub.status.idle": "2024-05-10T01:57:17.279376Z",
     "shell.execute_reply": "2024-05-10T01:57:17.278502Z",
     "shell.execute_reply.started": "2024-05-10T01:57:17.264016Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=7)\n",
    "        self.conv2 = nn.Conv2d(6, 30, kernel_size=7)\n",
    "        self.conv3 = nn.Conv2d(30, 120, kernel_size=7)\n",
    "        self.conv4 = nn.Conv2d(120, 120, kernel_size=7)\n",
    "        \n",
    "        self.sub = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(120*4*4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 29)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.batch_norm = nn.BatchNorm1d(512)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.sub(F.relu(self.conv1(x)))\n",
    "        x = self.sub(F.relu(self.conv2(x)))\n",
    "        x = self.sub(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        x = x.view(-1, 120*4*4)\n",
    "            \n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T02:41:56.212056Z",
     "iopub.status.busy": "2024-05-10T02:41:56.211676Z",
     "iopub.status.idle": "2024-05-10T02:41:56.218461Z",
     "shell.execute_reply": "2024-05-10T02:41:56.217316Z",
     "shell.execute_reply.started": "2024-05-10T02:41:56.212023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 30, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (conv3): Conv2d(30, 120, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (conv4): Conv2d(120, 120, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (sub): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1920, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=29, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T01:57:18.683498Z",
     "iopub.status.busy": "2024-05-10T01:57:18.683131Z",
     "iopub.status.idle": "2024-05-10T01:57:18.720469Z",
     "shell.execute_reply": "2024-05-10T01:57:18.719566Z",
     "shell.execute_reply.started": "2024-05-10T01:57:18.683468Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T01:57:23.228340Z",
     "iopub.status.busy": "2024-05-10T01:57:23.227466Z",
     "iopub.status.idle": "2024-05-10T02:13:38.431102Z",
     "shell.execute_reply": "2024-05-10T02:13:38.429614Z",
     "shell.execute_reply.started": "2024-05-10T01:57:23.228306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 3.2824165631984843 \tValidation Loss: 2.8745576765345433\n",
      "Validation loss decreased (inf --> 2.8745576765345433).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 2.104143702161723 \tValidation Loss: 1.1162338819997064\n",
      "Validation loss decreased (2.8745576765345433 --> 1.1162338819997064).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.9509252579732873 \tValidation Loss: 0.47591181020627077\n",
      "Validation loss decreased (1.1162338819997064 --> 0.47591181020627077).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.5229015865887718 \tValidation Loss: 0.2624741597422238\n",
      "Validation loss decreased (0.47591181020627077 --> 0.2624741597422238).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.327110498501309 \tValidation Loss: 0.18846143037937155\n",
      "Validation loss decreased (0.2624741597422238 --> 0.18846143037937155).  Saving model ...\n",
      "Training time: 975.191657781601 seconds ---\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "start_time = time.time()\n",
    "valid_loss_min = np.Inf \n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "       \n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "       \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    \n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "        \n",
    "    v_loss.append(train_loss)\n",
    "    t_loss.append(valid_loss)\n",
    "    print(f'Epoch: {epoch} \\tTraining Loss: {train_loss} \\tValidation Loss: {valid_loss}')\n",
    "    \n",
    "    \n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print(f'Training loss decreased ({valid_loss_min} --> {valid_loss}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        valid_loss_min = valid_loss\n",
    "        \n",
    "        \n",
    "print(\"Training time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T02:15:01.916193Z",
     "iopub.status.busy": "2024-05-10T02:15:01.915318Z",
     "iopub.status.idle": "2024-05-10T02:15:01.935483Z",
     "shell.execute_reply": "2024-05-10T02:15:01.934570Z",
     "shell.execute_reply.started": "2024-05-10T02:15:01.916155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T03:09:23.047331Z",
     "iopub.status.busy": "2024-05-10T03:09:23.046959Z",
     "iopub.status.idle": "2024-05-10T03:10:18.025897Z",
     "shell.execute_reply": "2024-05-10T03:10:18.024478Z",
     "shell.execute_reply.started": "2024-05-10T03:09:23.047300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1631, Accuracy: 16500.0/17400 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss = 0.0\n",
    "correct = 0.0\n",
    "\n",
    "pred = []\n",
    "true = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() \n",
    "        preds = output.argmax(dim=1, keepdim=True) \n",
    "        correct += preds.eq(target.view_as(preds)).sum().item()\n",
    "        \n",
    "        \n",
    "\n",
    "        preds = preds.cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        preds = np.reshape(preds,(len(preds),1))\n",
    "        target = np.reshape(target,(len(preds),1))\n",
    "        data = data.cpu().numpy()\n",
    "        for i in range(len(preds)):\n",
    "            pred.append(preds[i])\n",
    "            true.append(target[i])\n",
    "\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-10T03:10:28.449110Z",
     "iopub.status.busy": "2024-05-10T03:10:28.448694Z",
     "iopub.status.idle": "2024-05-10T03:10:29.493384Z",
     "shell.execute_reply": "2024-05-10T03:10:29.492247Z",
     "shell.execute_reply.started": "2024-05-10T03:10:28.449078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 94.96083962002571 Recall: 94.77833782682039 f1_score: 94.79495534871947\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "precision = metrics.precision_score(true,pred,average='macro')\n",
    "recall = metrics.recall_score(true,pred,average='macro')\n",
    "f1_score = metrics.f1_score(true,pred,average='macro')\n",
    "\n",
    "print(f'Precision: {precision*100} Recall: {recall*100} f1_score: {f1_score*100}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 23079,
     "sourceId": 29550,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4211775,
     "sourceId": 7266311,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
